{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary analysis\n",
    "## First dataset: df_duplicated_with_path\n",
    "\n",
    "This notebook requires first running the script \"download_dataset.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/raw/df_duplicated_with_path.pkl', 'rb') as file:\n",
    "    df1 = pd.compat.pickle_compat.load(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tweet has multiple associated images, there is an entry in the dataset for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second dataset: df_no_duplicated_with_path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/raw/df_no_duplicated_with_path2.pkl', 'rb') as file:\n",
    "    df2 = pd.compat.pickle_compat.load(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as dataset 1 but there is a single entry for each tweet, with all image paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third dataset: merged_df_with_gold_freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/raw/merged_df_with_gold_freq1.pkl', 'rb') as file:\n",
    "    df3 = pd.compat.pickle_compat.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds gold labels to dataset 2. Columns with name in the form of T_x are the gold labels for text only and contain the score for emotion x. T_gold_multi_label contains a list of emotions for which that entry has a non-zero score. Columns with name M_x are the same, but for the multimodal gold labels. The gold labels are those assigned manually. They are 900 entries of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3[\"M_gold_multi_label\"].notnull()][:4].filter(regex=(\"M_*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3[\"M_gold_multi_label\"].notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth dataset: merged_df_with_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/raw/merged_df_with_gold.pkl', 'rb') as file:\n",
    "    df4 = pd.compat.pickle_compat.load(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of this dataset is the same as the previous one and only differs in the contents of the gold multi label fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset differs to the previous one only in the gold label field. Whereas dataset 3 includes in that field labels with a score different from 0, this one only does if it is higher than 2. NaN values mean that the fields are equal. Around 100 entries (not necessarily the same ones) have the same labels for both multimodal and text only labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.compare(df4).isnull().sum())\n",
    "df3.compare(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all this both the third and fourth datasets are suitable for further analysis but it could also be helpful to merge the two by keeping both columns. The label column names are also renamed for future convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"label_M_gold_main\"] = df4[\"M_gold_multi_label\"]\n",
    "df3[\"label_M_gold_multi\"] = df3[\"M_gold_multi_label\"]\n",
    "\n",
    "df3[\"label_T_gold_main\"] = df4[\"T_gold_multi_label\"]\n",
    "df3[\"label_T_gold_multi\"] = df3[\"T_gold_multi_label\"]\n",
    "\n",
    "df3 = df3.drop(columns = [\"M_gold_multi_label\", \"T_gold_multi_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the dataset\n",
    "Some of the columns are not useful for the task so they can be dropped. First of all, any field relating to the user who posted the tweet can be dropped. There are also many fields which have a single value across all entries, some of them being simply null.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns=[\"name\", \"user_id\", \"user_id_str\", \"user_rt\", \"user_rt_id\", \"username\",\n",
    "                    \"video\", \"translate\", \"trans_dest\", \"trans_src\", \"timezone\", \"geo\", \"hour\", \"day\", \"near\",\n",
    "                    \"created_at\", \"retweet\", \"retweet_date\", \"retweet_id\", \"reply_to\", \"source\", \"place\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some other fields that can be dropped as they are not useful.<br>\n",
    "<ul>\n",
    "    <li>\"quote_url\" contains, if present, the link to the tweet being replied to.</li>\n",
    "    <li>\"urls\" contains any links present in the text of the tweet.</li>\n",
    "    <li>\"thumbnail\" is the link to the picture used as the thumbnail of the tweet and is a replica of one of the images linked in \"photos\".</li>\n",
    "    <li>\"photos\" can also be dropped as it only contains the links to the images in the tweet, which are already stored locally.</li>\n",
    "    <li>\"link\" simply contains the link to the tweet so it can be dropped as well.</li>\n",
    "    <li>The \"cashtags\" and \"hashtags\" fields are redundant as that text is already present in the text of the tweet.</li>\n",
    "    <li>\"date\", as the name implies, contains the timestamp of the tweet.</li>\n",
    "</ul>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns=[\"quote_url\", \"urls\", \"thumbnail\", \"photos\", \"link\", \"cashtags\", \"hashtags\", \"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"conversation_id\" contains some kind of ID which is in some cases different from the ID of the tweet. Nonetheless, it seems to be useless in our case so it can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3[\"conversation_id\"].compare(df3[\"id\"]))\n",
    "df3 = df3.drop(columns=[\"conversation_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"path_photos\" contains the local paths to the images, but the file names are simply the ID of the tweet with a number appended to the end, so it is sufficient to store the number of pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.loc[0, \"path_photos\"])\n",
    "print(df3.loc[0, \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"img_count\"] = df3[\"path_photos\"].apply(len)\n",
    "df3 = df3.drop(columns=[\"path_photos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"language\" column is mostly useless, as only 8 rows have a different value from \"en\". Additionally, only 2 of those with language \"fr\" are actually in the correct language, the others are stil in English. None of them have gold labels either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.loc[df3[\"language\"]!=\"en\", [\"tweet\", \"label_M_gold_multi\"]])\n",
    "df3 = df3.drop(columns = [\"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking for null values we can see that \"old_label\" is missing in the vast majority of the dataset so it would not be particularly useful. It is also unclear what it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.isnull().sum())\n",
    "df3 = df3.drop(columns=[\"old_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the remaining columns are not directly useful for our task, but might be interesting for some kind of analysis, for example relating emotions with said fields. They are the following:\n",
    "<ul>\n",
    "    <li>nlikes</li>\n",
    "    <li>nreplies</li>\n",
    "    <li>nretweets</li>\n",
    "    <li>search</li>\n",
    "    <li>seeds</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns are now left:\n",
    "<ul>\n",
    "    <li>id: id of the tweet.</li>\n",
    "    <li>tweet: text of the tweet.</li>\n",
    "    <li>nlikes: number of likes.</li>\n",
    "    <li>nreplies: number of replies.</li>\n",
    "    <li>nretweets: number of retweets.</li>\n",
    "    <li>search: the search used to retrieve the tweet.</li>\n",
    "    <li>seeds: the words that retrieved the tweet separated by emotion with a score of how \"strongly\" it embodies that emotion.</li>\n",
    "    <li>uni_label: the emotion with the highest score in seeds.</li>\n",
    "    <li>multi_label: all the emotions in seeds.</li>\n",
    "    <li>M_x: gold multimodal labels, one for each emotion. Contains the score of for that emotion.</li>\n",
    "    <li>T_x: gold text-only label, one for each emotion. Contains the score of for that emotion.</li>\n",
    "    <li>label_M_gold_main: list of emotions with a multimodal score of at least 2.</li>\n",
    "    <li>label_M_gold_multi: list of emotions with a multimodal score of at least 1.</li>\n",
    "    <li>label_T_gold_main: list of emotions with a text only score of at least 2.</li>\n",
    "    <li>label_T_gold_multi: list of emotions with a text only score of at least 1.</li>\n",
    "    <li>img_count: number of images of the tweet.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold and silver label split\n",
    "\n",
    "Now that the dataset is cleaned up it is useful to separate data with gold labels and data with only silver labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = df3[df3[\"M_Anger\"].notnull()].copy().reset_index(drop=True)\n",
    "print(gold_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gold dataset it might also be useful to modify the scores for the gold labels so that they sum to 1 over a single row, both for multimodal and text only labels. (Implemented but not actually used currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently not enabled\n",
    "\n",
    "\n",
    "# cols = gold_df.columns[gold_df.columns.str.startswith(\"M_\")]\n",
    "# gold_df[cols] = gold_df[cols].div(gold_df[cols].sum(axis=1), axis=0)\n",
    "\n",
    "# cols = gold_df.columns[gold_df.columns.str.startswith(\"T_\")]\n",
    "# gold_df[cols] = gold_df[cols].div(gold_df[cols].sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting gold labels to lowercase for consistency with silver labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = gold_df.columns[gold_df.columns.str.startswith(\"label_\")]\n",
    "for column in cols:\n",
    "    gold_df[column] = gold_df[column].apply(lambda x : [y.lower() for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images in the gold label dataset from the zip file containing all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "gold_dir = \"dataset/gold_images\"\n",
    "\n",
    "with ZipFile(\"dataset/raw/images.zip\") as zfile:\n",
    "    for i, row in gold_df.iterrows():\n",
    "        for n in range(0, row[\"img_count\"]):\n",
    "            file_name = f\"{row['id']}_{n}.jpg\"\n",
    "            if not os.path.isfile(f\"{gold_dir}/twint_images3/{file_name}\"):\n",
    "                zfile.extract(f\"twint_images3/{file_name}\", gold_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df = df3[df3[\"M_Anger\"].isnull()].reset_index(drop=True)\n",
    "print(silver_df.shape)\n",
    "silver_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images in the silver label dataset from the zip file containing all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# silver_dir = \"dataset/silver_images\"\n",
    "\n",
    "# with ZipFile(\"dataset/raw/images.zip\") as zfile:\n",
    "#     for i, row in silver_df.iterrows():\n",
    "#         for n in range(0, row[\"img_count\"]):\n",
    "#             file_name = f\"{row['id']}_{n}.jpg\"\n",
    "#             if not os.path.isfile(f\"{silver_dir}/twint_images3/{file_name}\"):\n",
    "#                 zfile.extract(f\"twint_images3/{file_name}\", silver_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the datasets to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.to_pickle(\"dataset/gold_label_dataset.pkl\")\n",
    "silver_df.to_csv(\"dataset/silver_label_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
