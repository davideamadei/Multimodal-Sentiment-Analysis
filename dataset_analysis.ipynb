{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/gold_label_dataset.pkl', 'rb') as file:\n",
    "    df = pd.compat.pickle_compat.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_M_gold_main\"].apply(len)>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"label_M_gold_main\"].apply(len)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 166\n",
    "i = 30\n",
    "print(df[df[\"label_M_gold_main\"].apply(len)>1].iloc[i].seeds)\n",
    "df[df[\"label_M_gold_main\"].apply(len)>1].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = df.columns[df.columns.str.startswith(\"M_\")].values.tolist()\n",
    "emotions = [e[2:].lower() for e in emotions]\n",
    "emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"label_\")].tolist()\n",
    "freq_counts = {e: dict.fromkeys(emotions, 0) for e in cols}\n",
    "for index, row in df.iterrows():\n",
    "    for column in cols:\n",
    "        for elem in row[column]:\n",
    "            freq_counts[column][elem] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the emotions are overrepresented, specifically \"joy\" and \"something else\". On the other hand, \"fear\" and \"trust\" are somewhat underrepresented. This is true for all types of labels, as the distribution is mostly the same across them, with some minor differences between multimodal and text only labels. In general the disparity in number of entries is less extreme in the text only labels. <br>\n",
    "<!-- TODO: find better phrasing -->\n",
    "The presence of a large number of entries with the \"something else\" label suggests that the emotions used as labels are not sufficient to express the range of emotions contained in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize = (13, 9))\n",
    "for i, ax in enumerate(axs.reshape(-1)):\n",
    "    ax.bar(freq_counts[cols[i]].keys(), freq_counts[cols[i]].values())\n",
    "    ax.set_title(cols[i])\n",
    "    bars = ax.bar(freq_counts[cols[i]].keys(), freq_counts[cols[i]].values())\n",
    "    ax.bar_label(bars, freq_counts[cols[i]].values())\n",
    "    labels = ax.get_xticklabels()\n",
    "    for i, label in enumerate(labels):\n",
    "        label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "fig.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also 34 entries which have an empty main gold multimodal label (which means none of the emotions have a score of at least 2). For the text only label there are 11 empy entries. These will need to be handled in some way. A possible solution might be to take the labels considering scores of at least 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label_M_gold_main\"].apply(len)==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check on score columns as well instead of list with labels. The number of samples where no emotion has a score greater than or equal to 2 is the same in both cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask checking for scores greater than or equal to 2\n",
    "mask = df[[f\"M_{x.capitalize()}\" for x in emotions]].ge(2)\n",
    "\n",
    "# check if on a row there is at least one emotion with score greater than or equal to 2 and print number of rows where it is true or false\n",
    "mask.any(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples to remove considering each tweet-image pair as a separate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i, row in df[~mask.any(axis=1)].iterrows():\n",
    "    sum += row[\"img_count\"]\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label_T_gold_main\"].apply(len)==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask checking for scores greater than or equal to 2\n",
    "mask = df[[f\"T_{x.capitalize()}\" for x in emotions]].ge(2)\n",
    "\n",
    "# check if on a row there is at least one emotion with score greater than or equal to 2 and print number of rows where it is true or false\n",
    "mask.any(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples to remove considering each tweet-image pair as a separate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i, row in df[~mask.any(axis=1)].iterrows():\n",
    "    sum += row[\"img_count\"]\n",
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most samples have multiple labels, even when considering a threshold of 2. Some emotions appear by themselves much less often than others. The ones that appear alone most often are joy, neutral and something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"label_\")].tolist()\n",
    "freq_counts = {e: dict.fromkeys(emotions, 0) for e in cols}\n",
    "\n",
    "for e in emotions:\n",
    "    for column in cols:\n",
    "        freq_counts[column][e] = df[(df[column].apply(lambda x: e in x)) & (df[column].apply(len)==1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize = (13, 9))\n",
    "for i, ax in enumerate(axs.reshape(-1)):\n",
    "    ax.bar(freq_counts[cols[i]].keys(), freq_counts[cols[i]].values())\n",
    "    ax.set_title(cols[i])\n",
    "    bars = ax.bar(freq_counts[cols[i]].keys(), freq_counts[cols[i]].values())\n",
    "    ax.bar_label(bars, freq_counts[cols[i]].values())\n",
    "    labels = ax.get_xticklabels()\n",
    "    for i, label in enumerate(labels):\n",
    "        label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "fig.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(cols[:2]):\n",
    "    fig, ax= plt.subplots(figsize = (6,4))\n",
    "    # ax.bar(freq_counts[col].keys(), freq_counts[col].values())\n",
    "    # ax.set_title(cols[i])\n",
    "    bars = ax.bar([e.capitalize() for e in emotions], freq_counts[col].values())\n",
    "    ax.bar_label(bars, freq_counts[col].values())\n",
    "    # labels = ax.get_xticklabels()\n",
    "    # for i, label in enumerate(labels):\n",
    "    #     label.set_y(label.get_position()[1] - (i % 2) * 0.055)\n",
    "    ax.set_ylabel(\"Number of tweets\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# fig.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting distribution of number of votes for each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "options = df.columns[df.columns.str.startswith(\"M_\")].values.tolist()\n",
    "options = [x[2:] for x in options]\n",
    "\n",
    "drop_down = widgets.Dropdown(options = options,\n",
    "                             value = \"Joy\",\n",
    "                             description = \"Emotion\",\n",
    "                             disabled = False)\n",
    "\n",
    "def dropdown_handler(emotion):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "    values = df[f\"M_{emotion}\"].value_counts()\n",
    "\n",
    "    bars = axes[0].bar(values.index.values, values.values)\n",
    "    axes[0].bar_label(bars, values.values)\n",
    "    axes[0].set_title(f\"Score distribution for {emotion} (Multimodal)\")\n",
    "\n",
    "    values = df[f\"T_{emotion}\"].value_counts()\n",
    "\n",
    "    bars = axes[1].bar(values.index.values, values.values)\n",
    "    axes[1].bar_label(bars, values.values)\n",
    "    axes[1].set_title(f\"Score distribution for {emotion} (Text only)\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "w = interactive(dropdown_handler, emotion = drop_down)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.M_Joy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")]\n",
    "\n",
    "count_dict = {emotion: None for emotion in emotions}\n",
    "\n",
    "tmp = df[cols].astype(int)\n",
    "\n",
    "for col, emotion in zip(cols, emotions):\n",
    "    count_dict[emotion] = tmp[col].value_counts().sort_index()\n",
    "for key, value in count_dict.items():\n",
    "    for i in range(len(value)-2, -1, -1):\n",
    "        value.iloc[i] += value.iloc[i+1]\n",
    "tmp = pd.DataFrame.from_dict(count_dict).fillna(0).astype(int)\n",
    "tmp = tmp.drop(0)\n",
    "ax = tmp.plot(kind=\"bar\", figsize=(10,4), rot=0)\n",
    "ax.legend([e.capitalize() for e in emotions])\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Number of tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = tmp.columns.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")]\n",
    "\n",
    "rename_dict = {col: emotion for col, emotion in zip(cols, emotions)}\n",
    "\n",
    "print(df[cols].astype(bool).sum(axis=0).rename(rename_dict).to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")]\n",
    "\n",
    "rename_dict = {col: emotion for col, emotion in zip(cols, emotions)}\n",
    "\n",
    "print((df[cols]>=2).sum(axis=0).rename(rename_dict).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[df.columns.str.startswith(\"M_\") | df.columns.str.startswith(\"T_\")].values.tolist()].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the number of images for each emotion where the sample only has that emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down = widgets.Dropdown(options = emotions,\n",
    "                             description = \"Emotion\",\n",
    "                             value = \"something else\",\n",
    "                             disabled = False)\n",
    "\n",
    "def dropdown_handler(emotion):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "    values = df.loc[df[\"label_M_gold_main\"].apply(lambda x : emotion in x and len(x)==1)][\"img_count\"].value_counts()\n",
    "\n",
    "    bars = axes[0].bar(values.index.values, values.values)\n",
    "    axes[0].bar_label(bars, values.values)\n",
    "    axes[0].set_title(f\"Number of images for {emotion} only samples (Multimodal)\")\n",
    "\n",
    "    values = df.loc[df[\"label_T_gold_main\"].apply(lambda x : emotion in x and len(x)==1)][\"img_count\"].value_counts()\n",
    "\n",
    "    bars = axes[1].bar(values.index.values, values.values)\n",
    "    axes[1].bar_label(bars, values.values)\n",
    "    axes[1].set_title(f\"Number of images for {emotion} only samples (Text only)\")\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "w = interactive(dropdown_handler, emotion = drop_down)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the number of images for each emotion where the sample has that emotion as one of its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down = widgets.Dropdown(options = emotions,\n",
    "                             description = \"Emotion\",\n",
    "                             value = \"something else\",\n",
    "                             disabled = False)\n",
    "\n",
    "def dropdown_handler(emotion):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "    values = df.loc[df[\"label_M_gold_main\"].apply(lambda x : emotion in x)][\"img_count\"].value_counts()\n",
    "\n",
    "    bars = axes[0].bar(values.index.values, values.values)\n",
    "    axes[0].bar_label(bars, values.values)\n",
    "    axes[0].set_title(f\"Number of images for {emotion} samples (Multimodal)\")\n",
    "\n",
    "    values = df.loc[df[\"label_T_gold_main\"].apply(lambda x : emotion in x)][\"img_count\"].value_counts()\n",
    "\n",
    "    bars = axes[1].bar(values.index.values, values.values)\n",
    "    axes[1].bar_label(bars, values.values)\n",
    "    axes[1].set_title(f\"Number of images for {emotion} samples (Text only)\")\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "w = interactive(dropdown_handler, emotion = drop_down)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples to be dropped:\n",
    "<ul>\n",
    "    <li> 96 for multimodal labels (138 considering a sample for each image)</li>\n",
    "    <li> 70 for txt only labels (95 considering a sample for each image)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_label_samples = df.loc[df[\"label_M_gold_main\"].apply(len)==0].shape[0]\n",
    "print(empty_label_samples + freq_counts[\"label_M_gold_main\"][\"something else\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_counts[\"label_M_gold_main\"][\"something else\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"label_M_gold_main\"\n",
    "tot = 0\n",
    "for i, row in df.iterrows():\n",
    "    if len(row[label])==0 or (\"something else\" in row[label] and len(row[label])==1):\n",
    "        tot += row[\"img_count\"]\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_label_samples = df.loc[df[\"label_T_gold_main\"].apply(len)==0].shape[0]\n",
    "print(empty_label_samples + freq_counts[\"label_T_gold_main\"][\"something else\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"label_T_gold_main\"\n",
    "tot = 0\n",
    "for i, row in df.iterrows():\n",
    "    if len(row[label])==0 or (\"something else\" in row[label] and len(row[label])==1):\n",
    "        tot += row[\"img_count\"]\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between silver and gold labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that only a small part of the dataset has gold labels it is a good idea to check how much the gold and silver labels differ from one another so as to know the quality of the silver labels.<br>\n",
    "\n",
    "There are two types of silver labels: \"uni_label\" and \"multi_label\". The first one contains only the highest scoring label, the second one is a list of all the emotions with a non-zero score. The score is the one given by the seeds, which are the words contained in the tweet which carry some kind of emotional meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the gold labels with the \"uni_label\" it is enough to check if the \"uni_label\" appears in the gold label as well. This holds for all types of gold labels.<br>\n",
    "\n",
    "From the bar plot we can see that the silver label is quite inaccurate. Even considering the more lax gold labels only slightly more than half of the samples have a label that appears in the gold label. With the more restrictive gold labels this decreases to around a third of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"label_\")].tolist()\n",
    "count_dict = {}\n",
    "for column in cols:\n",
    "    count = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if row[\"uni_label\"] not in row[column]:\n",
    "            count += 1\n",
    "    count_dict[column] = count\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bars = ax.bar(count_dict.keys(), count_dict.values())\n",
    "ax.bar_label(bars, count_dict.values())\n",
    "labels = ax.get_xticklabels()\n",
    "for i, label in enumerate(labels):\n",
    "    label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "ax.set_title(\"Difference with uni label\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"multi_label\" the comparison is slightly more involved, as it is a list instead of a single element. A rough way to do it is by checking if said list is disjoint with the gold label.<br>\n",
    "\n",
    "Compared to the \"uni_label\" these silver labels have slightly better results, but this is partially because of the way the comparison is done, as even a single emotion being in both labels counts as a positive example. Thus, results are still quite bad in this case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cols:\n",
    "    count = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if set(row[\"multi_label\"]).isdisjoint(row[column]):\n",
    "            count += 1\n",
    "    count_dict[column] = count\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bars = ax.bar(count_dict.keys(), count_dict.values())\n",
    "ax.bar_label(bars, count_dict.values())\n",
    "labels = ax.get_xticklabels()\n",
    "for i, label in enumerate(labels):\n",
    "    label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "ax.set_title(\"Difference with multi label\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between labels by emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")].values.tolist()\n",
    "cols = [x[2:].lower() for x in cols]\n",
    "label_types = [\"label_M_gold_main\", \"label_M_gold_multi\"]\n",
    "\n",
    "for type in label_types:\n",
    "\n",
    "    counter_dict = {col:0 for col in cols}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for label in row[type]:\n",
    "            if label in row[\"uni_label\"]:\n",
    "                counter_dict[label] += 1\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bars = ax.bar(counter_dict.keys(), counter_dict.values())\n",
    "    ax.bar_label(bars, counter_dict.values())\n",
    "    labels = ax.get_xticklabels()\n",
    "    for i, label in enumerate(labels):\n",
    "        label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "    ax.set_title(f\"Difference with multi label by emotion for {type}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")].values.tolist()\n",
    "cols = [x[2:].lower() for x in cols]\n",
    "label_types = [\"label_M_gold_main\", \"label_M_gold_multi\"]\n",
    "\n",
    "for type in label_types:\n",
    "\n",
    "    counter_dict = {col:0 for col in cols}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for label in row[type]:\n",
    "            if label in row[\"multi_label\"]:\n",
    "                counter_dict[label] += 1\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bars = ax.bar(counter_dict.keys(), counter_dict.values())\n",
    "    ax.bar_label(bars, counter_dict.values())\n",
    "    labels = ax.get_xticklabels()\n",
    "    for i, label in enumerate(labels):\n",
    "        label.set_y(label.get_position()[1] - (i % 2) * 0.075)\n",
    "    ax.set_title(f\"Difference with multi label by emotion for {type}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.columns.str.startswith(\"M_\")].values.tolist()\n",
    "cols = [x[2:].lower() for x in cols]\n",
    "label_types = [\"label_M_gold_main\", \"label_M_gold_multi\"]\n",
    "\n",
    "counter_dict = {type: {col:0 for col in cols} for type in label_types}\n",
    "\n",
    "for type in label_types:\n",
    "    for i, row in df.iterrows():\n",
    "        for label in row[type]:\n",
    "            if label in row[\"multi_label\"]:\n",
    "                counter_dict[type][label] += 1\n",
    "\n",
    "pd.DataFrame(counter_dict).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "    count += len(row[\"seeds\"].keys())\n",
    "count/(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between text only and multimodal labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting comparison is between the multimodal and text only gold labels, as it allows us to get an early look at how much the perception of emotions changes when one or more images are added to the context as opposed to classification done only on text. As before, one way to do this comparison is by checking if the sets are disjoint.<br>\n",
    "\n",
    "Results differ quite a bit between the two types of gold label (depending on selection method, score higher than 1 or higher than 2). When considering a score higher than 2, thus a more selective gold label, 214 samples have completely disjoint gold labels, suggesting that images can, rather expectedly, make a difference to how the text is perceived by a reader.<br>\n",
    "\n",
    "With the less restrictive gold labels there is more overlap, which is to be expected simply because of the labels containing more emotions overall and the comparison checking only if they share at least one element.<br>\n",
    "\n",
    "One way to further analyze this topic might be checking how much the labels acrually overlap between each other instead of checking only if there is any overlap at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "    if set(row[\"label_M_gold_main\"]).isdisjoint(row[\"label_T_gold_main\"]):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "    if set(row[\"label_M_gold_multi\"]).isdisjoint(row[\"label_T_gold_multi\"]):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between label scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is about what one might expect in this case.<br>\n",
    "\n",
    "Correlation tends to be high when comparing the text only and multimodal scores of the same emotion. A notable exception to this is for the label \"something else\". The two labels have a correlation of 0.22, which, while positive, is lower than for the other labels. This might be caused by the fact that what is considered \"something else\" changes based on the presence or lack of images.<br>\n",
    "\n",
    "The correlation between different emotions is also not particularly surprising. In general positive emotions correalate positively among themselves and negative emotions do so as well, albeit more strongly than positive ones. Positive and negative emotions have negative correlation with each other too. Neutral and \"something else\" are also inversely correlated with every other label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7)) \n",
    "cols = df.columns[df.columns.str.startswith(\"M_\")].tolist()\n",
    "sns.heatmap(df[cols].corr(), annot = True, fmt = '.3f', ax=ax,\n",
    "             square=True)\n",
    "ax.set_xticklabels([e.capitalize() for e in emotions])\n",
    "ax.set_yticklabels([e.capitalize() for e in emotions])\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7)) \n",
    "cols = df.columns[df.columns.str.startswith(\"M_\")].tolist()\n",
    "sns.heatmap((df[cols]>=2).corr(), annot = True, fmt = '.3f', ax=ax,\n",
    "             square=True)\n",
    "ax.set_xticklabels([e.capitalize() for e in emotions])\n",
    "ax.set_yticklabels([e.capitalize() for e in emotions])\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top images for each emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 images for each emotion are plotted here, together with the corresponding tweets.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "images = []\n",
    "labels = []\n",
    "for e in emotions:\n",
    "    label = f\"M_{e.capitalize()}\"\n",
    "    for i, row in df.sort_values(label, ascending=False).head(10).iterrows():\n",
    "        if e == \"joy\":\n",
    "            print(row)\n",
    "        tweets.append(row[\"tweet\"])\n",
    "        images.append(f\"dataset/gold_images/twint_images3/{row['id']}_0.jpg\")\n",
    "        labels.append(label)\n",
    "\n",
    "ipyplot.plot_class_tabs(images, labels, custom_texts=tweets, show_url=False, img_width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {e:[] for e in emotions}\n",
    "tweets = {e:[] for e in emotions}\n",
    "for e in emotions:\n",
    "    label = f\"M_{e.capitalize()}\"\n",
    "    for i, row in df.sort_values(label, ascending=False).head(5).iterrows():\n",
    "        images[e].append(f\"dataset/gold_images/twint_images3/{row['id']}_0.jpg\")\n",
    "        tweets[e].append(row[\"tweet\"])\n",
    "imgs = images[\"joy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "table = \"\"\n",
    "build_path = lambda x: \"images/dataset/top5/\" + re.search(\"(?<=dataset/gold_images/twint_images3/)(.*).jpg\", x).group(1) + \".pdf\"\n",
    "includegraphics = lambda x: f\"\\\\centerincludegraphics[height=2cm]{{{x}}}\"\n",
    "count = 0\n",
    "for e, imgs in images.items():\n",
    "    table += \"\\\\begin{subfigure}[b]{\\\\textwidth}\\n\\\\centering\\n\"\n",
    "    for image in imgs:\n",
    "        table += includegraphics(build_path(image)) + \"\\n\\\\hfill\\n\"\n",
    "    table += f\"\\\\caption{{{e.capitalize()}}}\\n\\end{{subfigure}}\\n\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import img2pdf\n",
    "from PIL import Image\n",
    " \n",
    "convert_imgs = False\n",
    "\n",
    "if convert_imgs:\n",
    "    # storing image path\n",
    "    \n",
    "    # storing pdf path\n",
    "    for e, imgs in images.items():\n",
    "        pdfs = [\"./Tesi/images/dataset/top5/\" + re.search(\"(?<=dataset/gold_images/twint_images3/)(.*).jpg\", x).group(1) + \".pdf\" for x in imgs]\n",
    "        for img, pdf in zip(imgs, pdfs):\n",
    "            # opening image\n",
    "            image = Image.open(img)\n",
    "            \n",
    "            # converting into chunks using img2pdf\n",
    "            pdf_bytes = img2pdf.convert(image.filename)\n",
    "            \n",
    "            # opening or creating pdf file\n",
    "            file = open(pdf, \"wb\")\n",
    "            \n",
    "            # writing pdf files with chunks\n",
    "            file.write(pdf_bytes)\n",
    "            \n",
    "            # closing image file\n",
    "            image.close()\n",
    "            \n",
    "            # closing pdf file\n",
    "            file.close()\n",
    "        \n",
    "    # output\n",
    "    # print(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if convert_imgs:\n",
    "    src_files = imgs\n",
    "    for file_name in src_files:\n",
    "        # full_file_name = os.path.join(src, file_name)\n",
    "        if os.path.isfile(file_name):\n",
    "            shutil.copy(file_name, \"C:/Users/Utente/Desktop/Multimodal-Sentiment-Analysis/Tesi/images/dataset/top5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "images = []\n",
    "labels = []\n",
    "for e in emotions:\n",
    "    label = f\"T_{e.capitalize()}\"\n",
    "    for i, row in df.sort_values(label, ascending=False).head(10).iterrows():\n",
    "        tweets.append(f\"{i} \" + row[\"tweet\"])\n",
    "        images.append(f\"dataset/gold_images/twint_images3/{row['id']}_0.jpg\")\n",
    "        labels.append(label)\n",
    "\n",
    "ipyplot.plot_class_tabs(images, labels, custom_texts=tweets, show_url=False, img_width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot wordclouds\n",
    "\n",
    "# df is the dataset to use to plot the wordcloud\n",
    "# multimodal is a flag to know which labels to use\n",
    "# threshold is the minimum score to have in labels to be included in the wordcloud\n",
    "def plot_wordcloud(df:pd.DataFrame, multimodal:bool, threshold:float = 0):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(25, 10))\n",
    "\n",
    "    if multimodal:\n",
    "        label_type = \"M\"\n",
    "    else:\n",
    "        label_type = \"T\"\n",
    "\n",
    "    for e, ax in zip(emotions, axs.flat):\n",
    "        label = f\"{label_type}_{e.capitalize()}\"\n",
    "        combined_text = ' '.join(df.loc[df[label] >= threshold]['tweet'])\n",
    "\n",
    "        pattern = re.compile(\"&amp\")\n",
    "        combined_text = re.sub(pattern, \"\", combined_text)\n",
    "\n",
    "        # cleaning the tweet text, code inspired from https://medium.com/codex/making-wordcloud-of-tweets-using-python-ca114b7a4ef4\n",
    "        \n",
    "        # remove emoji\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "            \"]+\", flags=re.UNICODE)\n",
    "        combined_text = re.sub(emoji_pattern,'',combined_text)\n",
    "\n",
    "        # remove urls\n",
    "        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+?')\n",
    "        combined_text = re.sub(url_pattern,'', combined_text)\n",
    "\n",
    "        # remove @ mentions and hashes\n",
    "        hash_pattern = re.compile(\"#\")\n",
    "        combined_text = re.sub(hash_pattern,\"\",combined_text)\n",
    "\n",
    "        mention_pattern = re.compile(\"@[A-Za-z0–9_]+\")\n",
    "        combined_text = re.sub(mention_pattern,\"\",combined_text)\n",
    "        \n",
    "        # remove occurrences of &amp;\n",
    "        and_pattern = re.compile(\"&amp;\")\n",
    "        combined_text = re.sub(and_pattern,\"&\",combined_text)\n",
    "\n",
    "        wordcloud = (\n",
    "            WordCloud(max_font_size=70, \n",
    "                    max_words=80,       \n",
    "                    background_color=\"white\",\n",
    "                    min_word_length=3,\n",
    "                    width=500,\n",
    "                    height=500)\n",
    "            .generate(combined_text)\n",
    "        )\n",
    "        ax.set_title(e.capitalize(), fontsize=18)\n",
    "        ax.imshow(wordcloud)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # if multimodal:\n",
    "    #     plt.suptitle(\"Multimodal wordclouds\", fontsize=30)\n",
    "    # else:\n",
    "    #     plt.suptitle(\"Text only wordclouds\", fontsize=30)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the wordcloud for tweets labeled with \"fear\" there are less words than other wordclouds. A possible explanation is that there are less tweets with that label. The same does not happen for \"trust\" though, despite a similar number of samples. \"anticipation\" also has fewer words than other labels, but only slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df=df, multimodal=True, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar behaviour to multimodal, though \"sadness\" and \"something else\" also have sparse wordclouds. \"fear\" is less sparse compared to multimodal wordclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df=df, multimodal=False, threshold=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
